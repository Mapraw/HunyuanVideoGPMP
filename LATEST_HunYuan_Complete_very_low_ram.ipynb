{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6s_DyGswYezx",
    "outputId": "12666ca0-5a88-4b35-e74c-fe6a40fbad14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'HunyuanVideoGP'...\n",
      "remote: Enumerating objects: 698, done.\u001b[K\n",
      "remote: Counting objects: 100% (386/386), done.\u001b[K\n",
      "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
      "remote: Total 698 (delta 336), reused 288 (delta 272), pack-reused 312 (from 1)\u001b[K\n",
      "Receiving objects: 100% (698/698), 59.45 MiB | 19.70 MiB/s, done.\n",
      "Resolving deltas: 100% (421/421), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Mapraw/HunyuanVideoGPMP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNTI29j_aHY5",
    "outputId": "e21112ae-94fa-4fe9-eec0-8b8ba9c6139f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sageattention==1.0.6 in /opt/conda/lib/python3.11/site-packages (1.0.6)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn==2.7.2.post1\n",
    "!pip install sageattention==1.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CxMGp_4ZMeHj",
    "outputId": "fbb2585c-c07e-4620-c5f7-0268dd97f9e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/HunyuanVideoGP\n",
      "Requirement already satisfied: torch==2.5.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision==0.20.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.5.1+cu124)\n",
      "Collecting opencv-python==4.9.0.80 (from -r requirements.txt (line 4))\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting diffusers==0.30.2 (from -r requirements.txt (line 5))\n",
      "  Downloading diffusers-0.30.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting transformers==4.48.0 (from -r requirements.txt (line 6))\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting peft==0.14.0 (from -r requirements.txt (line 7))\n",
      "  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tokenizers==0.21.0 (from -r requirements.txt (line 8))\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting accelerate==1.1.1 (from -r requirements.txt (line 9))\n",
      "  Downloading accelerate-1.1.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pandas==2.0.3 (from -r requirements.txt (line 10))\n",
      "  Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting numpy==1.24.4 (from -r requirements.txt (line 11))\n",
      "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting einops==0.7.0 (from -r requirements.txt (line 12))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tqdm==4.66.2 (from -r requirements.txt (line 13))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting loguru==0.7.2 (from -r requirements.txt (line 14))\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting imageio==2.34.0 (from -r requirements.txt (line 15))\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting imageio-ffmpeg==0.5.1 (from -r requirements.txt (line 16))\n",
      "  Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting safetensors==0.4.3 (from -r requirements.txt (line 17))\n",
      "  Downloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mmgp==3.0.9 (from -r requirements.txt (line 18))\n",
      "  Downloading mmgp-3.0.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting gradio==5.8.0 (from -r requirements.txt (line 19))\n",
      "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting moviepy==1.0.3 (from -r requirements.txt (line 20))\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch==2.5.1->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision==0.20.1->-r requirements.txt (line 2)) (10.2.0)\n",
      "Collecting importlib-metadata (from diffusers==0.30.2->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting huggingface-hub>=0.23.2 (from diffusers==0.30.2->-r requirements.txt (line 5))\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.30.2->-r requirements.txt (line 5))\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from diffusers==0.30.2->-r requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.0->-r requirements.txt (line 6)) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.48.0->-r requirements.txt (line 6)) (6.0.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.14.0->-r requirements.txt (line 7)) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==2.0.3->-r requirements.txt (line 10)) (2024.2)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.0.3->-r requirements.txt (line 10))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from imageio-ffmpeg==0.5.1->-r requirements.txt (line 16)) (72.1.0)\n",
      "Collecting optimum-quanto (from mmgp==3.0.9->-r requirements.txt (line 18))\n",
      "  Downloading optimum_quanto-0.2.6-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==5.8.0->-r requirements.txt (line 19)) (4.6.2.post1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.5.1 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from gradio==5.8.0->-r requirements.txt (line 19)) (0.27.2)\n",
      "Collecting markupsafe~=2.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting orjson~=3.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting pydantic>=2.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pydub (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting decorator<5.0,>=4.0.2 (from moviepy==1.0.3->-r requirements.txt (line 20))\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting proglog<=1.0.0 (from moviepy==1.0.3->-r requirements.txt (line 20))\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch==2.5.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==5.8.0->-r requirements.txt (line 19)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio==5.8.0->-r requirements.txt (line 19)) (1.3.1)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==5.8.0->-r requirements.txt (line 19)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio==5.8.0->-r requirements.txt (line 19)) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.8.0->-r requirements.txt (line 19)) (0.14.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.0->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.30.2->-r requirements.txt (line 5)) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->diffusers==0.30.2->-r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19)) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata->diffusers==0.30.2->-r requirements.txt (line 5)) (3.20.2)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.11/site-packages (from optimum-quanto->mmgp==3.0.9->-r requirements.txt (line 18)) (1.11.1.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19)) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.8.0->-r requirements.txt (line 19))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.30.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.48.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m127.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.1.1-py3-none-any.whl (333 kB)\n",
      "Downloading pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Downloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "Downloading imageio_ffmpeg-0.5.1-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmgp-3.0.9-py3-none-any.whl (27 kB)\n",
      "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading orjson-3.10.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.9.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m150.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Downloading optimum_quanto-0.2.6-py3-none-any.whl (165 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110711 sha256=1d00791fae590d9892954c44416838de36120a5e82d1e194b7d35f82c855572d\n",
      "  Stored in directory: /root/.cache/pip/wheels/83/b1/d9/119ef7c144b44d591ec0a9a140465133c23ea95d2a161184ba\n",
      "Successfully built moviepy\n",
      "Installing collected packages: pydub, websockets, uvicorn, tzdata, tqdm, tomlkit, shellingham, semantic-version, safetensors, ruff, regex, python-multipart, pydantic-core, orjson, numpy, mdurl, markupsafe, loguru, importlib-metadata, imageio-ffmpeg, ffmpy, einops, decorator, annotated-types, aiofiles, starlette, pydantic, proglog, pandas, opencv-python, markdown-it-py, imageio, huggingface-hub, tokenizers, safehttpx, rich, moviepy, gradio-client, fastapi, diffusers, typer, transformers, optimum-quanto, accelerate, peft, gradio, mmgp\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.5\n",
      "    Uninstalling tqdm-4.66.5:\n",
      "      Successfully uninstalled tqdm-4.66.5\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "Successfully installed accelerate-1.1.1 aiofiles-23.2.1 annotated-types-0.7.0 decorator-4.4.2 diffusers-0.30.2 einops-0.7.0 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.8.0 gradio-client-1.5.1 huggingface-hub-0.27.1 imageio-2.34.0 imageio-ffmpeg-0.5.1 importlib-metadata-8.5.0 loguru-0.7.2 markdown-it-py-3.0.0 markupsafe-2.1.5 mdurl-0.1.2 mmgp-3.0.9 moviepy-1.0.3 numpy-1.24.4 opencv-python-4.9.0.80 optimum-quanto-0.2.6 orjson-3.10.14 pandas-2.0.3 peft-0.14.0 proglog-0.1.10 pydantic-2.10.5 pydantic-core-2.27.2 pydub-0.25.1 python-multipart-0.0.20 regex-2024.11.6 rich-13.9.4 ruff-0.9.1 safehttpx-0.1.6 safetensors-0.4.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.3 tokenizers-0.21.0 tomlkit-0.13.2 tqdm-4.66.2 transformers-4.48.0 typer-0.15.1 tzdata-2024.2 uvicorn-0.34.0 websockets-14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd HunyuanVideoGPMP\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUKmLjdwMeFO",
    "outputId": "201e8acf-f705-4d87-9c8e-6d4b22c4ad6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "Fetching 10 files:   0%|                                 | 0/10 [00:00<?, ?it/s]\n",
      "text_encoder_2/special_tokens_map.json: 100%|██| 389/389 [00:00<00:00, 2.21MB/s]\u001b[A\n",
      "\n",
      "text_encoder_2/tokenizer.json:   0%|                | 0.00/2.22M [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "text_encoder_2/preprocessor_config.json: 100%|█| 316/316 [00:00<00:00, 1.39MB/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "text_encoder_2/merges.txt:   0%|                     | 0.00/525k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "text_encoder_2/readme.md: 100%|██████████████| 11.0/11.0 [00:00<00:00, 68.1kB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model.safetensors:   0%|                            | 0.00/1.71G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "text_encoder_2/config.json: 100%|██████████| 4.52k/4.52k [00:00<00:00, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "text_encoder_2/README.md: 100%|████████████| 7.95k/7.95k [00:00<00:00, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Fetching 10 files:  10%|██▌                      | 1/10 [00:00<00:03,  2.57it/s]\n",
      "text_encoder_2/tokenizer.json: 100%|███████| 2.22M/2.22M [00:00<00:00, 9.56MB/s]\u001b[A\n",
      "\n",
      "text_encoder_2/tokenizer.json: 100%|███████| 2.22M/2.22M [00:00<00:00, 9.46MB/s]\u001b[A\u001b[A\n",
      "text_encoder_2/merges.txt: 100%|█████████████| 525k/525k [00:00<00:00, 2.28MB/s]\n",
      "\n",
      "text_encoder_2/tokenizer_config.json: 100%|████| 905/905 [00:00<00:00, 5.67MB/s]\u001b[A\n",
      "Fetching 10 files:  30%|███████▌                 | 3/10 [00:00<00:01,  6.16it/s]\n",
      "text_encoder_2/vocab.json:   0%|                     | 0.00/961k [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   1%|                   | 10.5M/1.71G [00:00<01:05, 25.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "text_encoder_2/vocab.json: 100%|█████████████| 961k/961k [00:00<00:00, 2.80MB/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "model.safetensors:   1%|▏                  | 21.0M/1.71G [00:00<00:50, 33.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   2%|▎                  | 31.5M/1.71G [00:00<00:45, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   2%|▍                  | 41.9M/1.71G [00:01<00:42, 38.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   3%|▌                  | 52.4M/1.71G [00:01<00:41, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   4%|▋                  | 62.9M/1.71G [00:01<00:40, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   4%|▊                  | 73.4M/1.71G [00:01<00:39, 41.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   5%|▉                  | 83.9M/1.71G [00:02<00:38, 42.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   6%|█                  | 94.4M/1.71G [00:02<00:38, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   6%|█▏                  | 105M/1.71G [00:02<00:37, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   7%|█▎                  | 115M/1.71G [00:02<00:37, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   7%|█▍                  | 126M/1.71G [00:03<00:37, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   8%|█▌                  | 136M/1.71G [00:03<00:37, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   9%|█▋                  | 147M/1.71G [00:03<00:36, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:   9%|█▊                  | 157M/1.71G [00:03<00:36, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  10%|█▉                  | 168M/1.71G [00:04<00:36, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  10%|██                  | 178M/1.71G [00:04<00:36, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  11%|██▏                 | 189M/1.71G [00:04<00:36, 41.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  12%|██▎                 | 199M/1.71G [00:04<00:35, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  12%|██▍                 | 210M/1.71G [00:05<00:35, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  13%|██▌                 | 220M/1.71G [00:05<00:35, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  13%|██▋                 | 231M/1.71G [00:05<00:34, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  14%|██▊                 | 241M/1.71G [00:05<00:34, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  15%|██▉                 | 252M/1.71G [00:06<00:34, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  15%|███                 | 262M/1.71G [00:06<00:34, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  16%|███▏                | 273M/1.71G [00:06<00:33, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  17%|███▎                | 283M/1.71G [00:06<00:33, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  17%|███▍                | 294M/1.71G [00:07<00:33, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  18%|███▌                | 304M/1.71G [00:07<00:33, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  18%|███▋                | 315M/1.71G [00:07<00:32, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  19%|███▊                | 325M/1.71G [00:07<00:32, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  20%|███▉                | 336M/1.71G [00:08<00:32, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  20%|████                | 346M/1.71G [00:08<00:31, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  21%|████▏               | 357M/1.71G [00:08<00:31, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  21%|████▎               | 367M/1.71G [00:08<00:31, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  22%|████▍               | 377M/1.71G [00:09<00:31, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  23%|████▌               | 388M/1.71G [00:09<00:31, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  23%|████▋               | 398M/1.71G [00:09<00:30, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  24%|████▊               | 409M/1.71G [00:09<00:30, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  25%|████▉               | 419M/1.71G [00:10<00:30, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  25%|█████               | 430M/1.71G [00:10<00:32, 39.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  26%|█████▏              | 440M/1.71G [00:10<00:33, 37.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  26%|█████▎              | 451M/1.71G [00:10<00:32, 39.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  27%|█████▍              | 461M/1.71G [00:11<00:31, 40.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  28%|█████▌              | 472M/1.71G [00:11<00:30, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  28%|█████▋              | 482M/1.71G [00:11<00:29, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  29%|█████▊              | 493M/1.71G [00:11<00:29, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  29%|█████▉              | 503M/1.71G [00:12<00:28, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  30%|██████              | 514M/1.71G [00:12<00:28, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  31%|██████▏             | 524M/1.71G [00:12<00:27, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  31%|██████▎             | 535M/1.71G [00:12<00:27, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  32%|██████▍             | 545M/1.71G [00:13<00:27, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  32%|██████▍             | 556M/1.71G [00:13<00:27, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  33%|██████▌             | 566M/1.71G [00:13<00:26, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  34%|██████▋             | 577M/1.71G [00:13<00:26, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  34%|██████▊             | 587M/1.71G [00:14<00:26, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  35%|██████▉             | 598M/1.71G [00:14<00:25, 43.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  36%|███████             | 608M/1.71G [00:14<00:25, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  36%|███████▏            | 619M/1.71G [00:14<00:25, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  37%|███████▎            | 629M/1.71G [00:15<00:25, 42.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  37%|███████▍            | 640M/1.71G [00:15<00:25, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  38%|███████▌            | 650M/1.71G [00:15<00:24, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  39%|███████▋            | 661M/1.71G [00:15<00:24, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  39%|███████▊            | 671M/1.71G [00:16<00:24, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  40%|███████▉            | 682M/1.71G [00:16<00:24, 42.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  40%|████████            | 692M/1.71G [00:16<00:23, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  41%|████████▏           | 703M/1.71G [00:16<00:23, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  42%|████████▎           | 713M/1.71G [00:16<00:23, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  42%|████████▍           | 724M/1.71G [00:17<00:23, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  43%|████████▌           | 734M/1.71G [00:17<00:22, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  44%|████████▋           | 744M/1.71G [00:17<00:22, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  44%|████████▊           | 755M/1.71G [00:17<00:22, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  45%|████████▉           | 765M/1.71G [00:18<00:22, 42.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  45%|█████████           | 776M/1.71G [00:18<00:22, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  46%|█████████▏          | 786M/1.71G [00:18<00:21, 42.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  47%|█████████▎          | 797M/1.71G [00:18<00:21, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  47%|█████████▍          | 807M/1.71G [00:19<00:21, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  48%|█████████▌          | 818M/1.71G [00:19<00:21, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  48%|█████████▋          | 828M/1.71G [00:19<00:20, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  49%|█████████▊          | 839M/1.71G [00:19<00:21, 41.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  50%|█████████▉          | 849M/1.71G [00:20<00:20, 42.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  50%|██████████          | 860M/1.71G [00:20<00:20, 42.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  51%|██████████▏         | 870M/1.71G [00:20<00:19, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  51%|██████████▎         | 881M/1.71G [00:20<00:20, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  52%|██████████▍         | 891M/1.71G [00:21<00:19, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  53%|██████████▌         | 902M/1.71G [00:21<00:18, 43.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  53%|██████████▋         | 912M/1.71G [00:21<00:18, 42.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  54%|██████████▊         | 923M/1.71G [00:21<00:19, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  55%|██████████▉         | 933M/1.71G [00:22<00:19, 39.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  55%|███████████         | 944M/1.71G [00:22<00:20, 37.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  56%|███████████▏        | 954M/1.71G [00:22<00:20, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  56%|███████████▎        | 965M/1.71G [00:23<00:20, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  57%|███████████▍        | 975M/1.71G [00:23<00:20, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  58%|███████████▌        | 986M/1.71G [00:23<00:20, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  58%|███████████▋        | 996M/1.71G [00:24<00:20, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  59%|███████████▏       | 1.01G/1.71G [00:24<00:20, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  59%|███████████▎       | 1.02G/1.71G [00:24<00:19, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  60%|███████████▍       | 1.03G/1.71G [00:25<00:19, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  61%|███████████▌       | 1.04G/1.71G [00:25<00:19, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  61%|███████████▋       | 1.05G/1.71G [00:25<00:19, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  62%|███████████▊       | 1.06G/1.71G [00:25<00:18, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  63%|███████████▉       | 1.07G/1.71G [00:26<00:18, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  63%|███████████▉       | 1.08G/1.71G [00:26<00:18, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  64%|████████████       | 1.09G/1.71G [00:26<00:17, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  64%|████████████▏      | 1.10G/1.71G [00:27<00:17, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  65%|████████████▎      | 1.11G/1.71G [00:27<00:17, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  66%|████████████▍      | 1.12G/1.71G [00:27<00:16, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  66%|████████████▌      | 1.13G/1.71G [00:28<00:16, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  67%|████████████▋      | 1.14G/1.71G [00:28<00:16, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  67%|████████████▊      | 1.15G/1.71G [00:28<00:15, 35.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  68%|████████████▉      | 1.16G/1.71G [00:28<00:15, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  69%|█████████████      | 1.17G/1.71G [00:29<00:15, 34.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  69%|█████████████▏     | 1.18G/1.71G [00:29<00:14, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  70%|█████████████▎     | 1.20G/1.71G [00:29<00:14, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  70%|█████████████▍     | 1.21G/1.71G [00:30<00:14, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  71%|█████████████▌     | 1.22G/1.71G [00:30<00:14, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  72%|█████████████▋     | 1.23G/1.71G [00:30<00:13, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  72%|█████████████▋     | 1.24G/1.71G [00:30<00:13, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  73%|█████████████▊     | 1.25G/1.71G [00:31<00:13, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  74%|█████████████▉     | 1.26G/1.71G [00:31<00:12, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  74%|██████████████     | 1.27G/1.71G [00:31<00:13, 33.6MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  75%|██████████████▏    | 1.28G/1.71G [00:32<00:15, 27.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  75%|██████████████▎    | 1.29G/1.71G [00:32<00:14, 30.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  76%|██████████████▍    | 1.30G/1.71G [00:33<00:13, 29.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  77%|██████████████▌    | 1.31G/1.71G [00:33<00:13, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  77%|██████████████▋    | 1.32G/1.71G [00:33<00:13, 29.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  78%|██████████████▊    | 1.33G/1.71G [00:34<00:13, 29.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  78%|██████████████▉    | 1.34G/1.71G [00:34<00:12, 29.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  79%|███████████████    | 1.35G/1.71G [00:34<00:11, 30.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  80%|███████████████▏   | 1.36G/1.71G [00:35<00:11, 30.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  80%|███████████████▎   | 1.37G/1.71G [00:35<00:11, 30.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  81%|███████████████▎   | 1.38G/1.71G [00:35<00:10, 31.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  82%|███████████████▍   | 1.39G/1.71G [00:36<00:10, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  82%|███████████████▌   | 1.41G/1.71G [00:36<00:09, 31.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  83%|███████████████▋   | 1.42G/1.71G [00:36<00:09, 32.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  83%|███████████████▊   | 1.43G/1.71G [00:37<00:08, 32.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  84%|███████████████▉   | 1.44G/1.71G [00:37<00:08, 32.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  85%|████████████████   | 1.45G/1.71G [00:37<00:07, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  85%|████████████████▏  | 1.46G/1.71G [00:38<00:07, 33.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  86%|████████████████▎  | 1.47G/1.71G [00:38<00:07, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  86%|████████████████▍  | 1.48G/1.71G [00:38<00:06, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  87%|████████████████▌  | 1.49G/1.71G [00:39<00:06, 33.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  88%|████████████████▋  | 1.50G/1.71G [00:39<00:06, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  88%|████████████████▊  | 1.51G/1.71G [00:39<00:05, 34.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  89%|████████████████▉  | 1.52G/1.71G [00:39<00:05, 34.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  89%|█████████████████  | 1.53G/1.71G [00:40<00:05, 34.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  90%|█████████████████  | 1.54G/1.71G [00:40<00:04, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  91%|█████████████████▏ | 1.55G/1.71G [00:40<00:04, 34.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  91%|█████████████████▎ | 1.56G/1.71G [00:41<00:04, 35.0MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  92%|█████████████████▍ | 1.57G/1.71G [00:41<00:03, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  93%|█████████████████▌ | 1.58G/1.71G [00:41<00:03, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  93%|█████████████████▋ | 1.59G/1.71G [00:42<00:03, 34.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  94%|█████████████████▊ | 1.60G/1.71G [00:42<00:03, 35.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  94%|█████████████████▉ | 1.61G/1.71G [00:42<00:02, 35.3MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  95%|██████████████████ | 1.63G/1.71G [00:43<00:02, 31.5MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  96%|██████████████████▏| 1.64G/1.71G [00:43<00:02, 34.2MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  96%|██████████████████▎| 1.65G/1.71G [00:43<00:01, 36.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  97%|██████████████████▍| 1.66G/1.71G [00:43<00:01, 36.1MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  97%|██████████████████▌| 1.67G/1.71G [00:44<00:01, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  98%|██████████████████▋| 1.68G/1.71G [00:44<00:00, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  99%|██████████████████▊| 1.69G/1.71G [00:44<00:00, 35.9MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors:  99%|██████████████████▊| 1.70G/1.71G [00:44<00:00, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "model.safetensors: 100%|███████████████████| 1.71G/1.71G [00:45<00:00, 37.7MB/s]\u001b[A\u001b[A\u001b[A\n",
      "Fetching 10 files: 100%|████████████████████████| 10/10 [00:45<00:00,  4.56s/it]\n",
      "text_encoder/config.json: 100%|████████████████| 648/648 [00:00<00:00, 3.89MB/s]\n",
      "text_encoder/special_tokens_map.json: 100%|████| 577/577 [00:00<00:00, 3.35MB/s]\n",
      "text_encoder/tokenizer.json: 100%|█████████| 9.09M/9.09M [00:00<00:00, 15.7MB/s]\n",
      "text_encoder/tokenizer_config.json: 100%|███| 51.7k/51.7k [00:00<00:00, 128MB/s]\n",
      "(…)-llama-3-8b-v1_1_quanto_int8.safetensors: 100%|█| 8.03G/8.03G [03:11<00:00, 4\n",
      "(…)ava-llama-3-8b-v1_1_quanto_int8_map.json: 100%|█| 16.4k/16.4k [00:00<00:00, 8\n",
      "Fetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\n",
      "hunyuan-video-t2v-720p/vae/config.json: 100%|██| 627/627 [00:00<00:00, 3.42MB/s]\u001b[A\n",
      "Fetching 3 files:  33%|█████████                  | 1/3 [00:00<00:00,  3.67it/s]\n",
      "hunyuan-video-t2v-720p/vae/readme.md: 100%|██| 10.0/10.0 [00:00<00:00, 54.1kB/s]\u001b[A\n",
      "\n",
      "pytorch_model.pt:   0%|                              | 0.00/986M [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.pt:   1%|▏                    | 10.5M/986M [00:00<00:24, 40.6MB/s]\u001b[A\n",
      "pytorch_model.pt:   2%|▍                    | 21.0M/986M [00:00<00:23, 40.9MB/s]\u001b[A\n",
      "pytorch_model.pt:   3%|▋                    | 31.5M/986M [00:00<00:22, 41.7MB/s]\u001b[A\n",
      "pytorch_model.pt:   4%|▉                    | 41.9M/986M [00:01<00:22, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:   5%|█                    | 52.4M/986M [00:01<00:22, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:   6%|█▎                   | 62.9M/986M [00:01<00:21, 42.1MB/s]\u001b[A\n",
      "pytorch_model.pt:   7%|█▌                   | 73.4M/986M [00:01<00:21, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:   9%|█▊                   | 83.9M/986M [00:02<00:21, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  10%|██                   | 94.4M/986M [00:02<00:21, 41.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  11%|██▎                   | 105M/986M [00:02<00:21, 41.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  12%|██▌                   | 115M/986M [00:02<00:20, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  13%|██▊                   | 126M/986M [00:03<00:20, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  14%|███                   | 136M/986M [00:03<00:20, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  15%|███▎                  | 147M/986M [00:03<00:20, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:  16%|███▌                  | 157M/986M [00:03<00:19, 41.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  17%|███▋                  | 168M/986M [00:04<00:19, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:  18%|███▉                  | 178M/986M [00:04<00:19, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  19%|████▏                 | 189M/986M [00:04<00:19, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  20%|████▍                 | 199M/986M [00:04<00:18, 41.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  21%|████▋                 | 210M/986M [00:05<00:18, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  22%|████▉                 | 220M/986M [00:05<00:18, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:  23%|█████▏                | 231M/986M [00:05<00:17, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  24%|█████▍                | 241M/986M [00:05<00:17, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  26%|█████▌                | 252M/986M [00:06<00:17, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  27%|█████▊                | 262M/986M [00:06<00:17, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  28%|██████                | 273M/986M [00:06<00:17, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:  29%|██████▎               | 283M/986M [00:06<00:16, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  30%|██████▌               | 294M/986M [00:07<00:16, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  31%|██████▊               | 304M/986M [00:07<00:16, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  32%|███████               | 315M/986M [00:07<00:15, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  33%|███████▎              | 325M/986M [00:07<00:15, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  34%|███████▍              | 336M/986M [00:07<00:15, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  35%|███████▋              | 346M/986M [00:08<00:15, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  36%|███████▉              | 357M/986M [00:08<00:14, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  37%|████████▏             | 367M/986M [00:08<00:14, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  38%|████████▍             | 377M/986M [00:08<00:14, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  39%|████████▋             | 388M/986M [00:09<00:14, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  40%|████████▉             | 398M/986M [00:09<00:14, 41.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  41%|█████████             | 409M/986M [00:09<00:13, 41.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  43%|█████████▎            | 419M/986M [00:09<00:13, 41.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  44%|█████████▌            | 430M/986M [00:10<00:13, 41.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  45%|█████████▊            | 440M/986M [00:10<00:13, 41.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  46%|██████████            | 451M/986M [00:10<00:12, 41.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  47%|██████████▎           | 461M/986M [00:11<00:12, 41.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  48%|██████████▌           | 472M/986M [00:11<00:12, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  49%|██████████▊           | 482M/986M [00:11<00:11, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  50%|██████████▉           | 493M/986M [00:11<00:11, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  51%|███████████▏          | 503M/986M [00:11<00:11, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  52%|███████████▍          | 514M/986M [00:12<00:11, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  53%|███████████▋          | 524M/986M [00:12<00:10, 42.2MB/s]\u001b[A\n",
      "pytorch_model.pt:  54%|███████████▉          | 535M/986M [00:12<00:10, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  55%|████████████▏         | 545M/986M [00:12<00:10, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  56%|████████████▍         | 556M/986M [00:13<00:10, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  57%|████████████▋         | 566M/986M [00:13<00:09, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  58%|████████████▊         | 577M/986M [00:13<00:09, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  60%|█████████████         | 587M/986M [00:13<00:09, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  61%|█████████████▎        | 598M/986M [00:14<00:09, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  62%|█████████████▌        | 608M/986M [00:14<00:08, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  63%|█████████████▊        | 619M/986M [00:14<00:08, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  64%|██████████████        | 629M/986M [00:14<00:08, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  65%|██████████████▎       | 640M/986M [00:15<00:08, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  66%|██████████████▌       | 650M/986M [00:15<00:07, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  67%|██████████████▋       | 661M/986M [00:15<00:07, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  68%|██████████████▉       | 671M/986M [00:15<00:07, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  69%|███████████████▏      | 682M/986M [00:16<00:07, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  70%|███████████████▍      | 692M/986M [00:16<00:06, 42.1MB/s]\u001b[A\n",
      "pytorch_model.pt:  71%|███████████████▋      | 703M/986M [00:16<00:06, 42.1MB/s]\u001b[A\n",
      "pytorch_model.pt:  72%|███████████████▉      | 713M/986M [00:16<00:06, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  73%|████████████████▏     | 724M/986M [00:17<00:06, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  74%|████████████████▍     | 734M/986M [00:17<00:05, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  76%|████████████████▌     | 744M/986M [00:17<00:05, 42.5MB/s]\u001b[A\n",
      "pytorch_model.pt:  77%|████████████████▊     | 755M/986M [00:17<00:05, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  78%|█████████████████     | 765M/986M [00:18<00:05, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  79%|█████████████████▎    | 776M/986M [00:18<00:04, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  80%|█████████████████▌    | 786M/986M [00:18<00:04, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  81%|█████████████████▊    | 797M/986M [00:18<00:04, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  82%|██████████████████    | 807M/986M [00:19<00:04, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  83%|██████████████████▏   | 818M/986M [00:19<00:03, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  84%|██████████████████▍   | 828M/986M [00:19<00:03, 42.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  85%|██████████████████▋   | 839M/986M [00:19<00:03, 42.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  86%|██████████████████▉   | 849M/986M [00:20<00:03, 42.7MB/s]\u001b[A\n",
      "pytorch_model.pt:  87%|███████████████████▏  | 860M/986M [00:20<00:02, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  88%|███████████████████▍  | 870M/986M [00:20<00:02, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  89%|███████████████████▋  | 881M/986M [00:20<00:02, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  90%|███████████████████▉  | 891M/986M [00:21<00:02, 41.9MB/s]\u001b[A\n",
      "pytorch_model.pt:  91%|████████████████████  | 902M/986M [00:21<00:02, 41.8MB/s]\u001b[A\n",
      "pytorch_model.pt:  93%|████████████████████▎ | 912M/986M [00:21<00:01, 42.0MB/s]\u001b[A\n",
      "pytorch_model.pt:  94%|████████████████████▌ | 923M/986M [00:21<00:01, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  95%|████████████████████▊ | 933M/986M [00:22<00:01, 42.4MB/s]\u001b[A\n",
      "pytorch_model.pt:  96%|█████████████████████ | 944M/986M [00:22<00:00, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  97%|█████████████████████▎| 954M/986M [00:22<00:00, 42.6MB/s]\u001b[A\n",
      "pytorch_model.pt:  98%|█████████████████████▌| 965M/986M [00:22<00:00, 42.3MB/s]\u001b[A\n",
      "pytorch_model.pt:  99%|█████████████████████▊| 975M/986M [00:23<00:00, 40.0MB/s]\u001b[A\n",
      "pytorch_model.pt: 100%|██████████████████████| 986M/986M [00:23<00:00, 42.0MB/s]\u001b[A\n",
      "Fetching 3 files: 100%|███████████████████████████| 3/3 [00:23<00:00,  7.93s/it]\n",
      "(…)unyuan_video_720_quanto_int8.safetensors: 100%|█| 13.2G/13.2G [05:14<00:00, 4\n",
      "(…)s/hunyuan_video_720_quanto_int8_map.json: 100%|█| 24.7k/24.7k [00:00<00:00, 9\n",
      "\u001b[32m2025-01-13 16:03:25.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mGot text-to-video model root path: ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:25.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:25.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mLoading torch model ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors...\u001b[0m\n",
      "Pinning data of 'ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors' to reserved RAM\n",
      "The whole model was pinned to reserved RAM: 54 large blocks spread across 12580.24 MB\n",
      "\u001b[32m2025-01-13 16:03:38.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-t2v-720p/vae\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:41.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mVAE to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:41.946\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "\u001b[32m2025-01-13 16:03:42.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:42.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-13 16:03:42.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[1m\u001b[95m************ Memory Management for the GPU Poor (mmgp 3.0) by DeepBeepMeep ************\u001b[0m\u001b[0m\n",
      "You have chosen a profile that requires at least 32 GB of RAM and 12 GB of VRAM. Some RAM is consumed to reduce VRAM consumption. \n",
      "Model 'text_encoder' is already quantized to format 'qint8'\n",
      "Model 'transformer' already pinned to reserved memory\n",
      "* Running on local URL:  http://localhost:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "!python gradio_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyOyL4n3PozV",
    "outputId": "e6eec66e-0c66-4c6c-98d9-5c1d3716a460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/HunyuanVideoGP\n",
      "Namespace(quantize_transformer=False, lora_weight=[], lora_multiplier=[], profile=-1, verbose=1, server_port=0, server_name='', open_browser=False, model='HYVideo-T/2-cfgdistill', latent_channels=16, precision='bf16', rope_theta=256, vae='884-16c-hy', vae_precision='fp16', vae_tiling=True, text_encoder='llm', text_encoder_precision='fp16', text_states_dim=4096, text_len=256, tokenizer='llm', prompt_template='dit-llm-encode', prompt_template_video='dit-llm-encode-video', hidden_state_skip_layer=2, apply_final_norm=False, text_encoder_2='clipL', text_encoder_precision_2='fp16', text_states_dim_2=768, tokenizer_2='clipL', text_len_2=77, denoise_type='flow', flow_shift=7.0, flow_reverse=True, flow_solver='euler', use_linear_quadratic_schedule=False, linear_schedule_end=25, model_base='ckpts', dit_weight='ckpts/hunyuan-video-t2v-720p/transformers/mp_rank_00_model_states.pt', model_resolution='540p', load_key='module', use_cpu_offload=False, batch_size=1, infer_steps=35, disable_autocast=False, save_path='./results', save_path_suffix='', name_suffix='', num_videos=1, video_size=[640, 640], video_length=101, prompt='A cat walks on the country road, anime style.', seed_type='auto', seed=None, neg_prompt=None, cfg_scale=1.0, embedded_cfg_scale=6.0, reproduce=False, ulysses_degree=1, ring_degree=1)\n",
      "\u001b[32m2025-01-13 16:48:06.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mGot text-to-video model root path: ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:07.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m187\u001b[0m - \u001b[1mBuilding model...\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:07.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m201\u001b[0m - \u001b[1mLoading torch model ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors...\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:08.123\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLoading 3D VAE model (884-16c-hy) from: ./ckpts/hunyuan-video-t2v-720p/vae\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:11.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.vae\u001b[0m:\u001b[36mload_vae\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mVAE to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:11.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (llm) from: ./ckpts/text_encoder\u001b[0m\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
      "\u001b[32m2025-01-13 16:48:12.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mLoading text encoder model (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:12.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_text_encoder\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mText encoder to dtype: torch.float16\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:12.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.text_encoder\u001b[0m:\u001b[36mload_tokenizer\u001b[0m:\u001b[36m64\u001b[0m - \u001b[1mLoading tokenizer (clipL) from: ./ckpts/text_encoder_2\u001b[0m\n",
      "\u001b[1m\u001b[95m************ Memory Management for the GPU Poor (mmgp 3.0) by DeepBeepMeep ************\u001b[0m\u001b[0m\n",
      "You have chosen a profile that requires at least 32 GB of RAM and 12 GB of VRAM. Some RAM is consumed to reduce VRAM consumption. \n",
      "Model 'text_encoder' is already quantized to format 'qint8'\n",
      "Model 'transformer' is already quantized to format 'qint8'\n",
      "Pinning data of 'transformer' to reserved RAM\n",
      "The whole model was pinned to reserved RAM: 54 large blocks spread across 12580.24 MB\n",
      "\u001b[32m2025-01-13 16:48:25.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m587\u001b[0m - \u001b[1mInput (height, width, video_length) = (640, 640, 101)\u001b[0m\n",
      "\u001b[32m2025-01-13 16:48:25.297\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m647\u001b[0m - \u001b[34m\u001b[1m\n",
      "                        height: 640\n",
      "                         width: 640\n",
      "                  video_length: 101\n",
      "                        prompt: ['A cat walks on the country road, anime style.']\n",
      "                    neg_prompt: ['Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion']\n",
      "                          seed: None\n",
      "                   infer_steps: 35\n",
      "         num_videos_per_prompt: 1\n",
      "                guidance_scale: 1.0\n",
      "                      n_tokens: 41600\n",
      "                    flow_shift: 7.0\n",
      "       embedded_guidance_scale: 6.0\u001b[0m\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]self.enable_teacache 2 False\n",
      "  3%|█▎                                          | 1/35 [00:56<31:52, 56.26s/it]self.enable_teacache 2 False\n",
      "  6%|██▌                                         | 2/35 [01:54<31:29, 57.26s/it]self.enable_teacache 2 False\n",
      "  9%|███▊                                        | 3/35 [02:52<30:43, 57.60s/it]self.enable_teacache 2 False\n",
      " 11%|█████                                       | 4/35 [03:50<29:53, 57.86s/it]self.enable_teacache 2 False\n",
      " 14%|██████▎                                     | 5/35 [04:48<29:00, 58.00s/it]self.enable_teacache 2 False\n",
      " 17%|███████▌                                    | 6/35 [05:47<28:04, 58.10s/it]self.enable_teacache 2 False\n",
      " 20%|████████▊                                   | 7/35 [06:45<27:09, 58.19s/it]self.enable_teacache 2 False\n",
      " 23%|██████████                                  | 8/35 [07:43<26:12, 58.22s/it]self.enable_teacache 2 False\n",
      " 26%|███████████▎                                | 9/35 [08:42<25:15, 58.27s/it]self.enable_teacache 2 False\n",
      " 29%|████████████▎                              | 10/35 [09:40<24:16, 58.27s/it]self.enable_teacache 2 False\n",
      " 31%|█████████████▌                             | 11/35 [10:38<23:19, 58.31s/it]self.enable_teacache 2 False\n",
      " 34%|██████████████▋                            | 12/35 [11:36<22:20, 58.29s/it]self.enable_teacache 2 False\n",
      " 37%|███████████████▉                           | 13/35 [12:35<21:21, 58.23s/it]self.enable_teacache 2 False\n",
      " 40%|█████████████████▏                         | 14/35 [13:33<20:21, 58.17s/it]self.enable_teacache 2 False\n",
      " 43%|██████████████████▍                        | 15/35 [14:31<19:21, 58.10s/it]self.enable_teacache 2 False\n",
      " 46%|███████████████████▋                       | 16/35 [15:29<18:23, 58.06s/it]self.enable_teacache 2 False\n",
      " 49%|████████████████████▉                      | 17/35 [16:27<17:24, 58.05s/it]self.enable_teacache 2 False\n",
      " 51%|██████████████████████                     | 18/35 [17:24<16:26, 58.02s/it]self.enable_teacache 2 False\n",
      " 54%|███████████████████████▎                   | 19/35 [18:23<15:28, 58.04s/it]self.enable_teacache 2 False\n",
      " 57%|████████████████████████▌                  | 20/35 [19:21<14:31, 58.08s/it]self.enable_teacache 2 False\n",
      " 60%|█████████████████████████▊                 | 21/35 [20:19<13:33, 58.12s/it]self.enable_teacache 2 False\n",
      " 63%|███████████████████████████                | 22/35 [21:17<12:35, 58.14s/it]self.enable_teacache 2 False\n",
      " 66%|████████████████████████████▎              | 23/35 [22:16<11:38, 58.20s/it]self.enable_teacache 2 False\n",
      " 69%|█████████████████████████████▍             | 24/35 [23:14<10:40, 58.23s/it]self.enable_teacache 2 False\n",
      " 71%|██████████████████████████████▋            | 25/35 [24:12<09:42, 58.24s/it]self.enable_teacache 2 False\n",
      " 74%|███████████████████████████████▉           | 26/35 [25:10<08:44, 58.24s/it]self.enable_teacache 2 False\n",
      " 77%|█████████████████████████████████▏         | 27/35 [26:09<07:45, 58.24s/it]self.enable_teacache 2 False\n",
      " 80%|██████████████████████████████████▍        | 28/35 [27:07<06:48, 58.29s/it]self.enable_teacache 2 False\n",
      " 83%|███████████████████████████████████▋       | 29/35 [28:05<05:49, 58.27s/it]self.enable_teacache 2 False\n",
      " 86%|████████████████████████████████████▊      | 30/35 [29:03<04:51, 58.23s/it]self.enable_teacache 2 False\n",
      " 89%|██████████████████████████████████████     | 31/35 [30:01<03:52, 58.20s/it]self.enable_teacache 2 False\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [30:59<02:54, 58.12s/it]self.enable_teacache 2 False\n",
      " 94%|████████████████████████████████████████▌  | 33/35 [31:57<01:56, 58.02s/it]self.enable_teacache 2 False\n",
      " 97%|█████████████████████████████████████████▊ | 34/35 [32:55<00:57, 57.93s/it]self.enable_teacache 2 False\n",
      "100%|███████████████████████████████████████████| 35/35 [33:53<00:00, 58.09s/it]\n",
      "\u001b[32m2025-01-13 17:23:08.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mhyvideo.inference\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mSuccess, time: 2083.461204767227\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[32m2025-01-13 17:23:09.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m71\u001b[0m - \u001b[1mSample save to: ./results/2025-01-13-17:23:08_seed622838_A cat walks on the country road, anime style..mp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd HunyuanVideoGPMP\n",
    "\n",
    "!python3 sample_video.py \\\n",
    "    --video-size 640 640 \\\n",
    "    --video-length 101 \\\n",
    "    --infer-steps 35 \\\n",
    "    --prompt \"A cat walks on the country road, anime style.\" \\\n",
    "    --flow-reverse \\\n",
    "    --save-path ./results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w48BdfFWdStJ"
   },
   "outputs": [],
   "source": [
    "# change info in sample_video.py\n",
    "# 1. models_root_path = \"/content/HunyuanVideoGP/ckpts/hunyuan-video-t2v-720p/transformers/hunyuan_video_720_quanto_int8.safetensors\"\n",
    "# 2. text_encoder_filename = \"/content/HunyuanVideoGP/ckpts/text_encoder/llava-llama-3-8b-v1_1_quanto_int8.safetensors\"\n",
    "# 3.1 profile_type.VerylowRAM_LowVRAM\n",
    "# 3.2 LowRAM_LowVRAM  (at least 32 GB of RAM and 12 GB of VRAM : adapted for RTX 3090 / RTX 4090 with limited RAM but at the cost of VRAM (shorter videos))\n",
    "# 3.3 in models self.enable_teacache = False"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
